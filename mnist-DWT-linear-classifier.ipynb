{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd51d13c-d105-4f56-b06b-1f0b1fbf5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c430c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c13355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664c8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Transform: Normalize and Flatten Images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1, 28, 28))  # Flatten the image\n",
    "])\n",
    "\n",
    "# Load MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d791204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a function for DWT feature extraction\n",
    "def dwt_extract_features(images, wavelet='db1'):\n",
    "    \"\"\"\n",
    "    Extract features using Discrete Wavelet Transform (DWT).\n",
    "    Args:\n",
    "        images: A batch of images as a PyTorch tensor of shape [batch_size, 1, 28, 28].\n",
    "        wavelet: The type of wavelet to use (default is 'db1', Haar wavelet).\n",
    "    Returns:\n",
    "        Flattened DWT coefficients as a PyTorch tensor of shape [batch_size, num_features].\n",
    "    \"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    features = []\n",
    "    for i in range(batch_size):\n",
    "        # Convert PyTorch tensor to NumPy array\n",
    "        image = images[i, 0].cpu().numpy()\n",
    "\n",
    "        # Perform 2D Discrete Wavelet Transform\n",
    "        coeffs = pywt.dwt2(image, wavelet)\n",
    "        cA, (cH, cV, cD) = coeffs\n",
    "\n",
    "        # Flatten and concatenate coefficients (cA, cH, cV, cD)\n",
    "        flattened_coeffs = np.concatenate([cA.flatten(), cH.flatten(), cV.flatten(), cD.flatten()])\n",
    "        features.append(flattened_coeffs)\n",
    "\n",
    "    # Convert back to PyTorch tensor\n",
    "    return torch.tensor(features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8b5d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15390/1046000197.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(features, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract features for training and testing\n",
    "train_features = []\n",
    "test_features = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "wavelet = 'db1'  # Haar wavelet\n",
    "\n",
    "# Extract features for training data\n",
    "for images, labels in train_loader:\n",
    "    features = dwt_extract_features(images, wavelet)\n",
    "    train_features.append(features)\n",
    "    train_labels.append(labels)\n",
    "\n",
    "train_features = torch.cat(train_features, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "# Extract features for testing data\n",
    "for images, labels in test_loader:\n",
    "    features = dwt_extract_features(images, wavelet)\n",
    "    test_features.append(features)\n",
    "    test_labels.append(labels)\n",
    "\n",
    "test_features = torch.cat(test_features, dim=0)\n",
    "test_labels = torch.cat(test_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cf873c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 4: Define the Linear Classification Model\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize the linear classifier\n",
    "latent_dim = train_features.shape[1]  # Dimension of the latent representation\n",
    "num_classes = 10  # Number of MNIST classes\n",
    "classifier = LinearClassifier(latent_dim, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3410102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.3619, Accuracy: 89.65666961669922%\n",
      "Epoch [2/25], Loss: 0.2991, Accuracy: 91.61333465576172%\n",
      "Epoch [3/25], Loss: 0.2894, Accuracy: 91.9566650390625%\n",
      "Epoch [4/25], Loss: 0.2841, Accuracy: 92.14500427246094%\n",
      "Epoch [5/25], Loss: 0.2808, Accuracy: 92.26499938964844%\n",
      "Epoch [6/25], Loss: 0.2783, Accuracy: 92.34000396728516%\n",
      "Epoch [7/25], Loss: 0.2764, Accuracy: 92.41500091552734%\n",
      "Epoch [8/25], Loss: 0.2749, Accuracy: 92.46666717529297%\n",
      "Epoch [9/25], Loss: 0.2737, Accuracy: 92.52833557128906%\n",
      "Epoch [10/25], Loss: 0.2726, Accuracy: 92.56999969482422%\n",
      "Epoch [11/25], Loss: 0.2717, Accuracy: 92.6066665649414%\n",
      "Epoch [12/25], Loss: 0.2708, Accuracy: 92.62667083740234%\n",
      "Epoch [13/25], Loss: 0.2701, Accuracy: 92.65666961669922%\n",
      "Epoch [14/25], Loss: 0.2695, Accuracy: 92.66333770751953%\n",
      "Epoch [15/25], Loss: 0.2689, Accuracy: 92.68167114257812%\n",
      "Epoch [16/25], Loss: 0.2684, Accuracy: 92.68499755859375%\n",
      "Epoch [17/25], Loss: 0.2680, Accuracy: 92.70166778564453%\n",
      "Epoch [18/25], Loss: 0.2676, Accuracy: 92.7066650390625%\n",
      "Epoch [19/25], Loss: 0.2672, Accuracy: 92.72166442871094%\n",
      "Epoch [20/25], Loss: 0.2668, Accuracy: 92.7249984741211%\n",
      "Epoch [21/25], Loss: 0.2665, Accuracy: 92.74333190917969%\n",
      "Epoch [22/25], Loss: 0.2662, Accuracy: 92.75499725341797%\n",
      "Epoch [23/25], Loss: 0.2660, Accuracy: 92.75666809082031%\n",
      "Epoch [24/25], Loss: 0.2657, Accuracy: 92.76333618164062%\n",
      "Epoch [25/25], Loss: 0.2655, Accuracy: 92.77666473388672%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Linear Classifier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=1e-2)\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, len(train_features), 64):  # Batch processing\n",
    "        batch_data = train_features[i:i+64].to(device)  # Encoded vectors\n",
    "        batch_labels = train_labels[i:i+64].to(device)      # Corresponding labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = classifier(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        total += len(batch_labels)\n",
    "        correct += (predicted == batch_labels).sum()\n",
    "\n",
    "    avg_loss = running_loss / (len(train_features) // 64)\n",
    "    accuracy = 100 * correct / float(total)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a9732ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the trained classifier\n",
    "# torch.save(classifier.state_dict(), \"model/linear_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e05c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Linear Classifier: 91.54%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 7: Evaluate the Classifier\n",
    "classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_features), 64):\n",
    "        batch_data = test_features[i:i+64].to(device)\n",
    "        batch_labels = test_labels[i:i+64].to(device)\n",
    "\n",
    "        outputs = classifier(batch_data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy of the Linear Classifier: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f97a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_playing_with_dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
