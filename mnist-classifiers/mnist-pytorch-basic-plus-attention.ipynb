{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a0bf0fa7-c527-4fd3-b504-02a88fc94798",
    "_uuid": "1382c63fe24710d3b2840e7dcf172cddbf533743"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "59cdc9d5-da8f-4d7a-abc5-c62b0008afb0",
    "_uuid": "c6e0d7d3843719091564a580dbe08f67ee0d93ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 50\n",
    "\n",
    "# Transform: Normalize and Flatten Images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
    "])\n",
    "\n",
    "# Load MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d38db05-fad0-468c-9000-20caf5465eca",
    "_uuid": "ea9eba414f2f0f1e63ef564dc0ee708c753ff51f"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "### Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "3472f1c1-5888-4abe-822c-3a493a5f8be5",
    "_uuid": "cefd0bb2f23b80f30ca65cbb08859ad81ab12e08"
   },
   "outputs": [],
   "source": [
    "# Create ANN Model\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, 128) \n",
    "        self.att1 = nn.Linear(128, 128)  \n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.att2 = nn.Linear(64, 64)  \n",
    "\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.att3 = nn.Linear(32, 32)  \n",
    "\n",
    "        self.fc4 = nn.Linear(32, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # First layer\n",
    "        out1 = torch.relu(self.fc1(x))\n",
    "        att1 = torch.softmax(self.att1(out1), dim=1)  # Compute attention\n",
    "        out1 = out1 * att1  # Apply attention\n",
    "\n",
    "        # Second layer\n",
    "        out2 = torch.relu(self.fc2(out1))\n",
    "        att2 = torch.softmax(self.att2(out2), dim=1)\n",
    "        out2 = out2 * att2\n",
    "\n",
    "        # Third layer\n",
    "        out3 = torch.relu(self.fc3(out2))\n",
    "        att3 = torch.softmax(self.att3(out3), dim=1)\n",
    "        out3 = out3 * att3\n",
    "\n",
    "        # Output layer\n",
    "        out4 = self.fc4(out3)  # No Softmax here! (CrossEntropyLoss expects raw logits)\n",
    "\n",
    "        return out4\n",
    "\n",
    "\n",
    "model = ANNModel().to(device)\n",
    "error = nn.CrossEntropyLoss()\n",
    "# learning_rate = 0.02\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "7550e98b-5011-4d09-88ee-97b0ecbc6f19",
    "_uuid": "c91694f3af94e4e1b76ab01489e186718c70ccd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Loss: 0.0014, Acc: 47.9400%\n",
      "Epoch [1/50], Loss: 0.0007, Acc: 68.9000%\n",
      "Epoch [2/50], Loss: 0.0006, Acc: 73.3000%\n",
      "Epoch [3/50], Loss: 0.0003, Acc: 79.0000%\n",
      "Epoch [4/50], Loss: 0.0004, Acc: 83.4700%\n",
      "Epoch [5/50], Loss: 0.0005, Acc: 81.4600%\n",
      "Epoch [6/50], Loss: 0.0001, Acc: 85.1200%\n",
      "Epoch [7/50], Loss: 0.0002, Acc: 90.2000%\n",
      "Epoch [8/50], Loss: 0.0003, Acc: 92.6000%\n",
      "Epoch [9/50], Loss: 0.0005, Acc: 94.2300%\n",
      "Epoch [10/50], Loss: 0.0001, Acc: 94.4600%\n",
      "Epoch [11/50], Loss: 0.0001, Acc: 95.1200%\n",
      "Epoch [12/50], Loss: 0.0000, Acc: 94.8100%\n",
      "Epoch [13/50], Loss: 0.0000, Acc: 95.2900%\n",
      "Epoch [14/50], Loss: 0.0001, Acc: 95.2700%\n",
      "Epoch [15/50], Loss: 0.0007, Acc: 95.6500%\n",
      "Epoch [16/50], Loss: 0.0000, Acc: 95.7900%\n",
      "Epoch [17/50], Loss: 0.0001, Acc: 96.1000%\n",
      "Epoch [18/50], Loss: 0.0001, Acc: 94.3900%\n",
      "Epoch [19/50], Loss: 0.0000, Acc: 95.7800%\n",
      "Epoch [20/50], Loss: 0.0003, Acc: 95.2100%\n",
      "Epoch [21/50], Loss: 0.0001, Acc: 96.3300%\n",
      "Epoch [22/50], Loss: 0.0001, Acc: 96.2300%\n",
      "Epoch [23/50], Loss: 0.0000, Acc: 96.0400%\n",
      "Epoch [24/50], Loss: 0.0000, Acc: 96.2600%\n",
      "Epoch [25/50], Loss: 0.0000, Acc: 96.2100%\n",
      "Epoch [26/50], Loss: 0.0001, Acc: 96.1800%\n",
      "Epoch [27/50], Loss: 0.0000, Acc: 96.2200%\n",
      "Epoch [28/50], Loss: 0.0000, Acc: 96.4000%\n",
      "Epoch [29/50], Loss: 0.0001, Acc: 96.3100%\n",
      "Epoch [30/50], Loss: 0.0000, Acc: 94.9900%\n",
      "Epoch [31/50], Loss: 0.0000, Acc: 95.0200%\n",
      "Epoch [32/50], Loss: 0.0000, Acc: 96.4100%\n",
      "Epoch [33/50], Loss: 0.0000, Acc: 96.5400%\n",
      "Epoch [34/50], Loss: 0.0000, Acc: 96.4700%\n",
      "Epoch [35/50], Loss: 0.0000, Acc: 96.5700%\n",
      "Epoch [36/50], Loss: 0.0000, Acc: 96.3100%\n",
      "Epoch [37/50], Loss: 0.0000, Acc: 96.6100%\n",
      "Epoch [38/50], Loss: 0.0000, Acc: 96.6400%\n",
      "Epoch [39/50], Loss: 0.0001, Acc: 96.5500%\n",
      "Epoch [40/50], Loss: 0.0001, Acc: 96.7000%\n",
      "Epoch [41/50], Loss: 0.0000, Acc: 96.5400%\n",
      "Epoch [42/50], Loss: 0.0000, Acc: 96.6300%\n",
      "Epoch [43/50], Loss: 0.0000, Acc: 96.4700%\n",
      "Epoch [44/50], Loss: 0.0000, Acc: 96.2700%\n",
      "Epoch [45/50], Loss: 0.0001, Acc: 96.3400%\n",
      "Epoch [46/50], Loss: 0.0000, Acc: 96.6800%\n",
      "Epoch [47/50], Loss: 0.0000, Acc: 96.8500%\n",
      "Epoch [48/50], Loss: 0.0000, Acc: 96.8300%\n",
      "Epoch [49/50], Loss: 0.0001, Acc: 96.6200%\n"
     ]
    }
   ],
   "source": [
    "# Traning the Model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for (images, labels) in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "        \n",
    "    # Calculate Accuracy         \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Predict test dataset\n",
    "    for images, labels in test_loader: \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum()\n",
    "    \n",
    "    accuracy = 100 * correct / float(total)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "5579a7d6-7766-4d0f-b9d0-584cb4f28321",
    "_uuid": "c5e2e6da7f1ee801e38358dc28d4c99e32d2b761"
   },
   "outputs": [],
   "source": [
    "# # visualization loss \n",
    "# plt.plot(iteration_list,loss_list)\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"ANN: Loss vs Number of iteration\")\n",
    "# plt.show()\n",
    "\n",
    "# # visualization accuracy \n",
    "# plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"ANN: Accuracy vs Number of iteration\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "50bbb2e7-15d8-47f5-8f31-25e0d0cb9e29",
    "_uuid": "cd8f261d231acaccd0f0bc8466fc28c1b0c2f567"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "### Convolutional Neural Network (CNN)\n",
    "- CNN is well adapted to classify images.\n",
    "- You can learn CNN basics: https://www.kaggle.com/kanncaa1/convolutional-neural-network-cnn-tutorial\n",
    "- **Steps of CNN:**\n",
    "    1. Import Libraries\n",
    "    1. Prepare Dataset\n",
    "        - Totally same with previous parts.\n",
    "        - We use same dataset so we only need train_loader and test_loader. \n",
    "    1. Convolutional layer: \n",
    "        - Create feature maps with filters(kernels).\n",
    "        - Padding: After applying filter, dimensions of original image decreases. However, we want to preserve as much as information about the original image. We can apply padding to increase dimension of feature map after convolutional layer.\n",
    "        - We use 2 convolutional layer.\n",
    "        - Number of feature map is out_channels = 16\n",
    "        - Filter(kernel) size is 5*5\n",
    "    1. Pooling layer: \n",
    "        - Prepares a condensed feature map from output of convolutional layer(feature map) \n",
    "        - 2 pooling layer that we will use max pooling.\n",
    "        - Pooling size is 2*2\n",
    "    1. Flattening: Flats the features map\n",
    "    1. Fully Connected Layer: \n",
    "        - Artificial Neural Network that we learnt at previous part.\n",
    "        - Or it can be only linear like logistic regression but at the end there is always softmax function.\n",
    "        - We will not use activation function in fully connected layer.\n",
    "        - You can think that our fully connected layer is logistic regression.\n",
    "        - We combine convolutional part and logistic regression to create our CNN model.\n",
    "    1. Instantiate Model Class\n",
    "        - create model\n",
    "    1. Instantiate Loss\n",
    "        - Cross entropy loss\n",
    "        - It also has softmax(logistic function) in it.\n",
    "    1. Instantiate Optimizer\n",
    "        - SGD Optimizer\n",
    "    1. Traning the Model\n",
    "    1. Prediction\n",
    "- As a result, as you can see from plot, while loss decreasing, accuracy is increasing and our model is learning(training). \n",
    "- Thanks to convolutional layer, model learnt better and accuracy(almost 98%) is better than accuracy of ANN. Actually while tuning hyperparameters, increase in iteration and expanding convolutional neural network can increase accuracy but it takes too much running time that we do not want at kaggle.   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "9ca5af9e-6821-4d60-8084-edb523a39c6b",
    "_uuid": "4915535771ffdd33ef480200393216f215b4fc48"
   },
   "outputs": [],
   "source": [
    "# Create CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "error = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "99a8903c-da15-496c-96b7-f5402c8fc5f0",
    "_uuid": "f44e02d25698ac1a014795d972a384a3f3003d35"
   },
   "outputs": [],
   "source": [
    "# Traning the Model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for (images, labels) in train_loader:\n",
    "        images = images.to(device).view(-1, 1, 28, 28)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "        \n",
    "    # Calculate Accuracy         \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Predict test dataset\n",
    "    for images, labels in test_loader: \n",
    "        images = images.to(device).view(-1, 1, 28, 28)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum()\n",
    "    \n",
    "    accuracy = 100 * correct / float(total)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "ac9e4aee-b8af-4641-8794-bad03b650179",
    "_uuid": "44c1ed412d778f3e6b08f11bddc5321f63e408dd"
   },
   "outputs": [],
   "source": [
    "# # visualization loss \n",
    "# plt.plot(iteration_list,loss_list)\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "# plt.show()\n",
    "\n",
    "# # visualization accuracy \n",
    "# plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 18199,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env_playing_with_dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
